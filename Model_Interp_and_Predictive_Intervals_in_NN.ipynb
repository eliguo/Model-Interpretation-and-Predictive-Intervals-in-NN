{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nA9kNBMxuhp5"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from IPython.core.display import HTML"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(112358)\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "bZwMlJ6buklx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TITLE_FONTSIZE  = 14\n",
        "AXIS_LABEL_SIZE = 12"
      ],
      "metadata": {
        "id": "jklMqm7busAY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"contents\"></a>\n",
        "\n",
        "## Notebook Contents\n",
        "  \n",
        "  - [Overview and Data Description]\n",
        "  - [Questions]\n",
        "  - [Solutions]"
      ],
      "metadata": {
        "id": "CfaUj2XBwm47"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "<h2> Overview and Data Description </h2>\n",
        "<br /><br />\n",
        "    \n",
        "[Return to contents](#contents)\n",
        "\n",
        "<br /><br />\n",
        "In this problem, you will be building and interpreting models to predict whether a flight was delayed for its arrival based on features that could be measured as the flight takes off.  \n",
        "We will also estimate the predictive intervals of the model using bootstrapping. We will utilize those predictive intervals to build a new kind of model: a model that refrains from making a prediction when it is not confident.  \n",
        "\n",
        "\n",
        "The included variables are:\n",
        "<br /><br />\n",
        "**ARRIVAL_DELAY**: the difference between scheduled arrival and actual arrival, in minutes (positive is late, negative is early).\n",
        "<br /><br />\n",
        "**DISTANCE**: the distance between arrival and departure airports, in miles.\n",
        "<br /><br />\n",
        "**SCHEDULED_TIME**: the flight's scheduled travel time.\n",
        "<br /><br />\n",
        "**MONTH**: the month the flight took off, 1 = January, 2 = February, etc.\n",
        "<br /><br />\n",
        "**SCHED_DEP_HOUR**: the scheduled departure time (the hour of the day).\n",
        "<br /><br />\n",
        "**SCHED_ARR_HOUR**: the scheduled arrival time (the hour of the day).\n",
        "<br /><br />\n",
        "**FLIGHT_COUNT**: the number of flights flying out of that airport before noon on a typical day.\n",
        "<br /><br />\n",
        "**DAY_OF_WEEK**: the day of the week, 1 = Monday, 2 = Tuesday, etc.\n",
        "<br /><br />\n",
        "**ORIGIN_AIRPORT**: the airport the flight took off from.\n",
        "<br /><br />\n",
        "**DESTINATION_AIRPORT**: the airport the flight was scheduled to land at.\n",
        "<br /><br />\n",
        "For the airport codes, see: https://www.bts.gov/topics/airlines-and-airports/world-airport-codes\n",
        "\n",
        "To sucessfully complete this part, you will proceed by fitting a NN model, evaluating its accuracy, interpreting the predictors' importance, and finally evaluating the predictive intervals.\n",
        "<br /><br />\n",
        "**NOTE:** The observations were sampled so that roughly half of the observations were delayed and half of the observations were not delayed.\n",
        "\n",
        "</div> "
      ],
      "metadata": {
        "id": "m4mbG4UCxkNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "<h2>Questions</h2> \n",
        "<br /><br />\n",
        "    \n",
        "[Return to contents](#contents)\n",
        "\n",
        "<br /><br />\n",
        "**1.1**  Read in the dataset `flights.csv`. Create a variable `DELAY_OR_NOT` that denotes whether `ARRIVAL_DELAY` is greater than or equal to 15 minutes (the FAA and BTS define a flight as delayed only if it arrives 15 minutes late or more). This is going to be the response variable for the rest of this question. \n",
        "<br /><br />\n",
        "**1.2** Preprocess the data: one-hot-encode the non-numeric categorical variables, deal with missing values if there are any, scale your data, and split the data into training and test sets (use an 80/20 split with `random_state=111`). Print the resulting shapes of your $X$ and $y$ dataframes for both your train and your test sets.\n",
        "<br /><br />\n",
        "**2.** Fit an artificial neural network model using all predictors (name this model `NN_model`).  Use a dense feed-forward network with two hidden layers with 15 nodes in each hidden layer. For this network, use appropriate activation functions for each layer, select an appropriate loss function and optimizer, specify a validation split of 0.2, train for an appropriate number of epochs based on the results of your training and validation accuracy plot, and feel free to use the default batch size while training. Plot the training accuracy and validation accuracy as a function of epochs from your `NN_model` training history. Evaluate the `NN_model` model on both train and test, and print out the resulting train and test accuracies.\n",
        "<br /><br />\n",
        "**3.** To begin our interpretation of the resulting `NN_model`, we will first use a \"proxy model\" that we know how to interpret and train it on our `NN_model` training predictions.\n",
        "\n",
        "<br /><br />\n",
        "- **3.1** For this we need to modify our training set. First, generate a set of `NN_model` class predictions for the training set. These training predictions will be used to form a revised training dataset for our proxy model: (a) use all of the same $X$ values used by `NN_model` for our $X$ train and (b) replace the actual response values $y$ with the predicted $\\hat{y}$ values generated by the fitted `NN_model`.\n",
        "\n",
        "<br /><br />\n",
        "- **3.2** Next, fit a logistic regression model using your revised training dataset from 3.1 (name this model `logreg`). Use ridge-like regularization. Print the `logreg` test accuracy to confirm that it is similar to what we saw for our `NN_model` test accuracy in question 2. You may need to adjust `C` in order to achieve a similar accuracy.\n",
        "\n",
        "<br /><br />\n",
        "- **3.3** Now use sklearn's `permutation_importance` class (already included in this notebook's imports) to compute the feature importance using the `logreg` model.\n",
        "<br />\n",
        "  - Read the official documentation for `permutation_importance` [here](https://scikit-learn.org/stable/modules/permutation_importance.html#:~:text=The%20permutation%20feature%20importance%20is,model%20depends%20on%20the%20feature.) as well as [here](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html#sklearn.inspection.permutation_importance) to learn how it works.\n",
        "<br />\n",
        "  - You can use the default number of `n_repeats` and your estimator's default `scorer`. To speed up the time it takes to run your permutations, you can try setting `n_jobs=-1` to take full advantage of all of your available processor cores.\n",
        "<br />\n",
        "  - Measure the **relative** variable importance (i.e. as a proportion of the variable importance of the most important variable identified by `permutation_importance`) and generate a barplot illustrating the relative variable importances for the top-10 most important predictors identified using `permutation_importance`.\n",
        "<br /><br />\n",
        "\n",
        "**4.** Another way to interpret the  `NN_model` is by examining the response as a function of any of the predictors. Particularly, we will select from features often found most significant from the analysis above. **For all plots below**, for ease of interpretation, **please be certain to** display all predictors on their original scales. \n",
        "<br /><br />\n",
        "\n",
        "   - **4.1** Set all predictors to their means/modes except for `SCHED_DEP_HOUR`. Predict the probability of delay and plot the predicted probabilities of delay vs. `SCHED_DEP_HOUR` on the data from the **training set**. Interpret what you see in 2-4 sentences.\n",
        "<br /><br />\n",
        " \n",
        "   - **4.2** Set all predictors to their means/modes except for `SCHED_DEP_HOUR` and `FLIGHT_COUNT`. Predict the probability of delay and plot the predicted probabilities of delay vs. `SCHED_DEP_HOUR` and `FLIGHT_COUNT` from the training set.\n",
        "\n",
        "<br /><br />\n",
        "   - **4.3**   Set all predictors to their means/modes except for except for `SCHED_DEP_HOUR` and `SCHED_ARR_HOUR`. Predict the probability of delay and plot the predicted probabilities of delay vs. `SCHED_DEP_HOUR` and `SCHED_ARR_HOUR` from the training set.\n",
        "\n",
        "<br /><br />\n",
        "   - **4.4** Set all predictors to their means/modes except for except for `SCHED_DEP_HOUR` and `DISTANCE`. Predict the probability of delay and plot the predicted probabilities of delay vs. `SCHED_DEP_HOUR` and `DISTANCE` from the training set. \n",
        "<br /><br />\n",
        "\n",
        "  - **4.5** In 5-10 sentences, interpret what you have seen in 4.2, 4.3, and 4.4.\n",
        "<br /><br />\n",
        "**HINT:** For 4.2, 4.3, and 4.4, when you include `SCHED_DEP_HOUR` on one axis and your second predictor on the other axis, you can color your datapoints based on their corresponding predicted probabilities by using  the `c` and `cmap` arguments in `plt.scatter`. You can also add a labeled colorbar to your plot to make clear what those colors mean. Please refer to the matplotlib documentation for examples.\n",
        "<br /><br />\n",
        "    \n",
        "**5.**\n",
        "    \n",
        "<br /><br />\n",
        "In this part, we will attempt to do model inference. Neural Networks have too many parameters, and therefore inference on all the parameters is intractable and meaningless. \n",
        "<br /><br />\n",
        "Using the same network architecture as `NN_model` (layers, nodes, activations, etc.) and your scaled data from that model, create multiple training sets using bootstrapping and fit a separate neural network model to each bootstrapped set of data (a minimum of at least 50 bootstraps should be used). Predict the output on the test data for each model. Randomly select 8 test observations and on 8 subplots, plot the distribution of predicted probabilities (i.e. $n$ bootstrapped probabilites) with the 95% CI bounds clearly marked and reported in each subplot and the actual class of each observation included in each subplot's title for easy reference.\n",
        "    <br /><br />\n",
        "Interpret what you see in 3-5 sentences.\n",
        "<br /><br />\n",
        "    \n",
        "**NOTE:** The code for this problem can take an extremely long time to execute. Please feel free to use the provided `progressbar` function below to visually track the progress of your bootstraps.\n",
        "    \n",
        "<br /><br />\n",
        "    \n",
        "**6.**\n",
        "    \n",
        "<br /><br />\n",
        "Using the probability distribution of the predictions obtained from the bootstrapped samples above, we can evaluate how \"significant\" our bagged (i.e. bootstrap-aggregated) prediction will be for each test observation.\n",
        "<br /><br />\n",
        "To accomplish this, you will first calculate the ratio of bootstrapped probabilities that cross the threshold value of $\\hat{p}=0.5$. Let's call this ratio the **Posterior Prediction Ratio (PPR)**. When a bagged prediction's $PPR=0$, all predictions are compatible (i.e. all bootstrapped probabilities for that test observation are on the same side of $\\hat{p}=0.5$). Likewise, when the $PPR=0.5$, half of the bootstrapped predictions for that test observation are $\\hat{y}=0$, and the other half are $\\hat{y}=1$. After calculating your $PPR$ values for all test observations, you should have $n=2000$ $PPR$ values (i.e. one for each test observation).\n",
        "<br /><br />\n",
        "Next, to get more accurate predictions, we can create an **abstain** model that will abstain from making a prediction for a particular observation if some defined threshold for significance (i.e. maximum $PPR$ value) is not met. (If you'd like to learn more about abstain models, you can read more [here](https://openreview.net/forum?id=rJxF73R9tX).)\n",
        "<br /><br />\n",
        "Let's explore how your resulting test accuracies might change by using your bootstrapped prediction results from question 5 for an **abstain bagging model** (i.e. a bootstrap aggregated model where some test observations are simply not predicted based on a given $PPR$ threshold). You can make your abstain model *stricter* by using smaller $PPR$ threshold values.\n",
        "<br /><br />\n",
        "- Print the test accuracy for your **bagging model** predictions from question 5 using predictions for all 2,000 of our test observations. \n",
        "<br /><br />\n",
        "- Plot the test accuracies for an **abstain bagging model** using your predictions from question 5 as a function of increasing $PPR$.\n",
        "<br /><br />\n",
        "- Also, plot the proportion of test observations not abstained (i.e. the proportion of those predicted) for your **abstain bagging model** as a function of increasing $PPR$.\n",
        "<br /><br />\n",
        "- Interpret what you see in 3-5 sentences.\n",
        "<br /><br />\n",
        "    \n",
        "**NOTE**: You should observe that as $PPR$ decreases (more confident predictions), you must also compromise on the number of points that your abstain model predicts confidently. \n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "8CjPWFLcyFb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"part1solutions\"></a>\n",
        "\n",
        "## PART 1: Solutions\n",
        "\n",
        "[Return to contents](#contents)"
      ],
      "metadata": {
        "id": "YbmV1xnI0rZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class='exercise-r'>\n",
        "\n",
        "**1.**    \n",
        "\n",
        "**1.1**\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "1L-gHrH11PIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read in the dataset\n",
        "df = pd.read_csv('.\\\\data\\\\flights.csv')\n",
        "\n",
        "# create response variable DELAY_OR_NOT, dtype is bool\n",
        "DELAY_OR_NOT = (df[['ARRIVAL_DELAY']] >= 15)\n",
        "\n",
        "# replace True/False with 1/0\n",
        "DELAY_OR_NOT.replace([True,False], [1,0], inplace=True)\n",
        "\n",
        "# rename the response Series\n",
        "DELAY_OR_NOT.rename({'ARRIVAL_DELAY':'DELAY_OR_NOT'}, axis=1, inplace=True)\n",
        "\n",
        "# drop the response column in original df\n",
        "df.drop('ARRIVAL_DELAY', axis=1, inplace=True)\n",
        "\n",
        "# take a look at the response\n",
        "print(DELAY_OR_NOT.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "BPY5L8ya1SWl",
        "outputId": "052020f0-051f-487d-a776-e14af99c2dcd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-e164d220a8da>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# read in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.\\\\data\\\\flights.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# create response variable DELAY_OR_NOT, dtype is bool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mDELAY_OR_NOT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ARRIVAL_DELAY'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.\\\\data\\\\flights.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class='exercise-r'>  \n",
        "\n",
        "**1.2**\n",
        "    \n",
        "</div>"
      ],
      "metadata": {
        "id": "J9M4ogVi1ax1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# delete all missing values (by row)\n",
        "df.dropna(axis=0,how='any',inplace=True)\n",
        "\n",
        "# get all non-numeric columns\n",
        "# NOTE do day_of_week/month count as non-numeric categorical variables?\n",
        "non_numeric_cols = [\n",
        "    # 'MONTH', \n",
        "    # 'DAY_OF_WEEK', \n",
        "    'ORIGIN_AIRPORT',\n",
        "    'DESTINATION_AIRPORT']\n",
        "# non_numeric_cols = df.select_dtypes(exclude='number').columns\n",
        "\n",
        "# one-hot-encode the non-numeric columns, frop the first column\n",
        "one_hot_df = pd.get_dummies(df[non_numeric_cols], columns=non_numeric_cols, drop_first=True)\n",
        "\n",
        "# get all numeric columns\n",
        "numeric_cols = df.columns.drop(non_numeric_cols)\n",
        "\n",
        "# scale the numeric data with StandardScaler\n",
        "scaler = StandardScaler()\n",
        "std_array = scaler.fit_transform(df[numeric_cols])      # this method returns an array\n",
        "std_df = pd.DataFrame(std_array, columns=numeric_cols)  # convert array into dataframe\n",
        "\n",
        "# get predictors by concating one_hot_df with std_df\n",
        "X = pd.concat([std_df, one_hot_df], axis=1)\n",
        "\n",
        "# split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, DELAY_OR_NOT, test_size=0.2, random_state=111)\n",
        "\n",
        "# print the resulting shapes of dataframe for both train and test sets\n",
        "print(f'shape of train perdictor: {X_train.shape}')\n",
        "print(f'shape of train response : {y_train.shape}')\n",
        "print(f'shape of test  perdictor: {X_test.shape}')\n",
        "print(f'shape of test  response : {y_test.shape}')\n"
      ],
      "metadata": {
        "id": "K9_CFQ1U1cVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class='exercise-r'>  \n",
        "    \n",
        "**2.**\n",
        "    \n",
        "</div>"
      ],
      "metadata": {
        "id": "lrzxUD5i1jFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define my NN_model\n",
        "NN_model = tf.keras.Sequential()\n",
        "\n",
        "# add 2 hidden layer as requested\n",
        "NN_model.add(tf.keras.layers.Dense(15, input_dim=X_train.shape[1], activation='relu'))\n",
        "NN_model.add(tf.keras.layers.Dense(15, activation='relu'))\n",
        "\n",
        "# add output layer, use sigmoid as output activation\n",
        "NN_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))    # output layer\n"
      ],
      "metadata": {
        "id": "iETPzfbc1nOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS  = 6\n",
        "LOSS_   = 'binary_crossentropy' # tf.keras.losses.BinaryCrossentropy()\n",
        "OPTMZ_  = 'adam'                # tf.keras.optimizers.SGD()\n",
        "METRIC_ = ['accuracy']\n",
        "\n",
        "# compile the model\n",
        "NN_model.compile(\n",
        "    loss = LOSS_,\n",
        "    optimizer = OPTMZ_,\n",
        "    metrics = METRIC_\n",
        ")\n",
        "\n",
        "# fit the model\n",
        "history = NN_model.fit(\n",
        "    x = X_train,\n",
        "    y = y_train,\n",
        "    epochs = EPOCHS,\n",
        "    validation_split = 0.2,\n",
        "    verbose = 0\n",
        ")\n"
      ],
      "metadata": {
        "id": "Atc9G6DA1tOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot train and val acc as a function of epochs\n",
        "fig = plt.figure(num=1, figsize = (10,5))\n",
        "ax = fig.gca()\n",
        "ax.plot(history.history['accuracy'],color='#EFAEA4',label = 'Training Accuracy')\n",
        "ax.plot(history.history['val_accuracy'],color='#B2D7D0',label = 'Validation Accuracy')\n",
        "ax.legend()\n",
        "ax.set_xlabel('Epochs', fontsize=AXIS_LABEL_SIZE)\n",
        "ax.set_ylabel('Accuracy %', fontsize=AXIS_LABEL_SIZE)\n",
        "ax.set_title('Training Accuracy and Validation Accuracy for NN Model', fontsize = TITLE_FONTSIZE)\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "E4wtrcpj1wMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate NN_model on train and test dataset\n",
        "pred_train = NN_model.predict(X_train, verbose=0)\n",
        "pred_test = NN_model.predict(X_test, verbose=0)\n",
        "\n",
        "# print accuracy score (use .round() to get classes)\n",
        "print(\"NN_model train auccuracy:\", accuracy_score(y_train.values.reshape((-1,)), pred_train.round().reshape((-1,))))\n",
        "print(\"NN_model test  auccuracy:\", accuracy_score(y_test.values.reshape((-1,)), pred_test.round().reshape((-1,))))\n",
        "\n",
        "# print ROC accuracy score\n",
        "print(\"NN_model train roc_accuracy:\", roc_auc_score(y_train, pred_train))\n",
        "print(\"NN_model test  roc_accuracy:\", roc_auc_score(y_test, pred_test))\n"
      ],
      "metadata": {
        "id": "tcSw3E5l1y7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class='exercise-r'>\n",
        "\n",
        "**3.**\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "8yd5B1-R12MX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a set of NN_model class predictions for the training set\n",
        "pred_class = pred_train.round()\n",
        "\n",
        "# fit a logistic regression model using revised training dataset\n",
        "logreg = LogisticRegression(\n",
        "    C = 50,\n",
        "    penalty = 'l2',\n",
        "    solver = 'liblinear')\n",
        "logreg.fit(X_train, pred_class.reshape((-1,)))\n",
        "\n",
        "# evaluate logreg on test dataset\n",
        "pred_test_logreg_proba = logreg.predict_proba(X_test)\n",
        "pred_test_logreg = logreg.predict(X_test)\n",
        "\n",
        "# print ROC accuracy score and accuracy score\n",
        "print(f'Logreg test accuracy: {accuracy_score(y_test, pred_test_logreg)}')\n",
        "print(f'Logreg test roc_accuracy: {roc_auc_score(y_test, pred_test_logreg_proba[:,1])}')\n"
      ],
      "metadata": {
        "id": "LHlsqm2L13zO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculates the feature importance of estimators for a given dataset\n",
        "feature_importance = permutation_importance(\n",
        "    estimator = logreg, # trained model\n",
        "    X = X_test,         # validation input\n",
        "    y = y_test,         # validation output\n",
        "    n_repeats = 10,     # the number of times a feature is randomly shuffled and returns a sample of feature importances\n",
        "    n_jobs = -1,        # the number of local cores it use\n",
        ")\n"
      ],
      "metadata": {
        "id": "dxIlMftz18XX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get importances in the order of features\n",
        "importances = feature_importance.importances_mean\n",
        "\n",
        "# measure the relative variable\n",
        "max_importance = max(importances)\n",
        "r_importances = np.array([im/max_importance*100 for im in importances])\n",
        "\n",
        "# get sorted index based on importances value\n",
        "im_index_sorted = r_importances.argsort()[::-1]\n",
        "\n",
        "# plot a barchart to illustrate the top-10 relative variable importances\n",
        "x_data = np.linspace(1,10,10)\n",
        "y_data = r_importances[im_index_sorted[0:10]]\n",
        "\n",
        "fig = plt.figure(figsize=(10,5))\n",
        "ax = fig.gca()\n",
        "ax.set_title('Relative Variable Importances for Top-10 Most Important Predictors', fontsize=TITLE_FONTSIZE)\n",
        "ax.set_xlabel('Feature', fontsize=AXIS_LABEL_SIZE)\n",
        "ax.set_xticks(x_data,X_test.columns[im_index_sorted[0:10]], fontsize=8)\n",
        "ax.set_yscale('log')\n",
        "ax.set_ylabel('Proportion (log scale)',fontsize=AXIS_LABEL_SIZE)\n",
        "ax.bar(x_data, y_data)\n",
        "\n",
        "for x,y in zip(x_data,y_data):\n",
        "    ax.text(x+0.03,y+0.05,'%.2f'%y+'%',ha='center',va='bottom')\n",
        "    \n",
        "fig.autofmt_xdate()\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "N56-kblV1-al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class='exercise-r'>\n",
        "\n",
        "**4.**    \n",
        "\n",
        "**4.1**\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "A0pCoafd2LlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get means of numeric predictors and modes of one-hot predictors\n",
        "X_train_all_mean = X_train.mean()\n",
        "X_train_onehot_mode = X_train[one_hot_df.columns].mode().iloc[0]\n",
        "\n",
        "# set all the predictors except SCHED_DEP_HOUR to their mean/mode\n",
        "X_train_1 = X_train.copy()\n",
        "X_train_1[X_train_all_mean.index] = X_train_all_mean\n",
        "X_train_1[X_train_onehot_mode.index] = X_train_onehot_mode\n",
        "X_train_1['SCHED_DEP_HOUR'] = X_train['SCHED_DEP_HOUR']\n",
        "\n",
        "# predict delay with modified training set\n",
        "pred_train_1 = NN_model.predict(X_train_1, verbose=0)\n",
        "\n",
        "# get SCHED_DEP_HOUR data which are on original scale\n",
        "x_origin = pd.DataFrame(data=df['SCHED_DEP_HOUR'], index=X_train_1.index)\n",
        "\n",
        "# plot the predicted probabilities of delay vs. SCHED_DEP_HOUR\n",
        "fig = plt.figure(figsize=(10,5))\n",
        "ax = fig.gca()\n",
        "ax.set_title('Predicted Probabilities of Delay vs. Scheduled Departure Hour',fontsize=TITLE_FONTSIZE)\n",
        "ax.set_xlabel('Scheduled Departure Hour', fontsize=AXIS_LABEL_SIZE)\n",
        "ax.set_xticks(np.linspace(0,24,25))\n",
        "ax.set_ylabel('Predicted Probability of Delay', fontsize=AXIS_LABEL_SIZE)\n",
        "ax.scatter(x_origin, pred_train_1)\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "Sq3zcycf2PqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INTERPRETATION:**"
      ],
      "metadata": {
        "id": "xEO37WEQ2S5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The graph shows a relationship between DELAY and SCHEDUELED DEPARTURE HOUR. We set all other predictors to mean to isolate the effect of SCHED_DEP_HOUR on DELAY, while keeping all other predictors constant. This is based on the assumption that SCHED_DEP_HOUR has a greater effect, in other words, more important, to DELAY; otherwise, we might not get a obvious pattern from the graph."
      ],
      "metadata": {
        "id": "Rj7wNJSU2VMs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class='exercise-r'>\n",
        "\n",
        "**4.2**\n",
        "</div>"
      ],
      "metadata": {
        "id": "_Qa68oyi2aRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set all the predictors except SCHED_DEP_HOUR and FLIGHT_COUNT to their mean/mode\n",
        "X_train_2 = X_train.copy()\n",
        "X_train_2[X_train_all_mean.index] = X_train_all_mean\n",
        "X_train_2[X_train_onehot_mode.index] = X_train_onehot_mode\n",
        "X_train_2['SCHED_DEP_HOUR'] = X_train['SCHED_DEP_HOUR']\n",
        "X_train_2['FLIGHT_COUNT'] = X_train['FLIGHT_COUNT']\n",
        "\n",
        "# predict delay with modified training set\n",
        "pred_train_2 = NN_model.predict(X_train_2, verbose=0)\n",
        "\n",
        "# get SCHED_DEP_HOUR and FLIGHT_COUNT data which are on original scale\n",
        "x_origin = pd.DataFrame(data=df['SCHED_DEP_HOUR'], index=X_train_2.index)\n",
        "y_origin = pd.DataFrame(data=df['FLIGHT_COUNT'], index=X_train_2.index)\n",
        "\n",
        "# plot the predicted probabilities of delay vs. SCHED_DEP_HOUR and FLIGHT_HOUR\n",
        "fig = plt.figure(figsize=(10,5))\n",
        "ax = fig.gca()\n",
        "ax.set_title('Predicted Probabilities of Delay vs. Scheduled Departure Hour and Flight Count', fontsize=TITLE_FONTSIZE)\n",
        "ax.set_xlabel('Scheduled Departure Hour', fontsize=AXIS_LABEL_SIZE)\n",
        "ax.set_xticks(np.linspace(0,24,25))\n",
        "ax.set_ylabel('Flight Count', fontsize=AXIS_LABEL_SIZE)\n",
        "ax.scatter(x_origin, y_origin, c=pred_train_2, cmap='summer')\n",
        "clb = fig.colorbar(plt.cm.ScalarMappable(cmap='summer'), ax=ax, shrink=.9)\n",
        "clb.set_label('Predicted Probability of Delay', fontsize=AXIS_LABEL_SIZE)\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "J39rD4oA2eVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class='exercise-r'>\n",
        "\n",
        "**4.3**\n",
        "    \n",
        "</div>"
      ],
      "metadata": {
        "id": "5nCCoxBa2iiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set all the predictors except SCHED_DEP_HOUR and SCHED_ARR_HOUR to their mean/mode\n",
        "X_train_3 = X_train.copy()\n",
        "X_train_3[X_train_all_mean.index] = X_train_all_mean\n",
        "X_train_3[X_train_onehot_mode.index] = X_train_onehot_mode\n",
        "X_train_3['SCHED_DEP_HOUR'] = X_train['SCHED_DEP_HOUR']\n",
        "X_train_3['SCHED_ARR_HOUR'] = X_train['SCHED_ARR_HOUR']\n",
        "\n",
        "# predict delay with modified training set\n",
        "pred_train_3 = NN_model.predict(X_train_3, verbose=0)\n",
        "\n",
        "# get SCHED_DEP_HOUR and SCHED_ARR_HOUR data which are on original scale\n",
        "x_origin = pd.DataFrame(data=df['SCHED_DEP_HOUR'], index=X_train_3.index)\n",
        "y_origin = pd.DataFrame(data=df['SCHED_ARR_HOUR'], index=X_train_3.index)\n",
        "\n",
        "# plot the predicted probabilities of delay vs. SCHED_DEP_HOUR and SCHED_ARR_HOUR\n",
        "fig = plt.figure(figsize=(10,5))\n",
        "ax = fig.gca()\n",
        "ax.set_title('Predicted Probabilities of Delay vs. Scheduled Departure Hour and Scheduled Arrival Hour', fontsize=TITLE_FONTSIZE)\n",
        "ax.set_xlabel('Scheduled Departure Hour', fontsize=AXIS_LABEL_SIZE)\n",
        "ax.set_xticks(np.linspace(0,24,25))\n",
        "ax.set_ylabel('Scheduled Arrival Hour', fontsize=AXIS_LABEL_SIZE)\n",
        "ax.scatter(x_origin, y_origin, c=pred_train_3, cmap='summer')\n",
        "clb = fig.colorbar(plt.cm.ScalarMappable(cmap='summer'), ax=ax, shrink=.9)\n",
        "clb.set_label('Predicted Probability of Delay', fontsize=AXIS_LABEL_SIZE)\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "C2dIORce2pV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set all the predictors except SCHED_DEP_HOUR and DISTANCE to their mean/mode\n",
        "X_train_4 = X_train.copy()\n",
        "X_train_4[X_train_all_mean.index] = X_train_all_mean\n",
        "X_train_4[X_train_onehot_mode.index] = X_train_onehot_mode\n",
        "X_train_4['SCHED_DEP_HOUR'] = X_train['SCHED_DEP_HOUR']\n",
        "X_train_4['DISTANCE'] = X_train['DISTANCE']\n",
        "\n",
        "# predict delay with modified training set\n",
        "pred_train_4 = NN_model.predict(X_train_4, verbose=0)\n",
        "\n",
        "# get SCHED_DEP_HOUR and DISTANCE data which are on original scale\n",
        "x_origin = pd.DataFrame(data=df['SCHED_DEP_HOUR'], index=X_train_4.index)\n",
        "y_origin = pd.DataFrame(data=df['DISTANCE'], index=X_train_4.index)\n",
        "\n",
        "# plot the predicted probabilities of delay vs. SCHED_DEP_HOUR and DISTANCE\n",
        "fig = plt.figure(figsize=(10,5))\n",
        "ax = fig.gca()\n",
        "ax.set_title('Predicted Probabilities of Delay vs. Scheduled Departure Hour and Distance', fontsize=TITLE_FONTSIZE)\n",
        "ax.set_xlabel('Scheduled Departure Hour', fontsize=AXIS_LABEL_SIZE)\n",
        "ax.set_xticks(np.linspace(0,24,25))\n",
        "ax.set_ylabel('Distance', fontsize=AXIS_LABEL_SIZE)\n",
        "ax.scatter(x_origin, y_origin, c=pred_train_4, cmap='summer')\n",
        "clb = fig.colorbar(plt.cm.ScalarMappable(cmap='summer'), ax=ax, shrink=.9)\n",
        "clb.set_label('Predicted Probability of Delay', fontsize=AXIS_LABEL_SIZE)\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "3NPoE17D2ryT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INTERPRETATION:**"
      ],
      "metadata": {
        "id": "dmxWep0L2vx2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In all models from 1.4.2 to 1.4.4, we assumed that SCHED_DEP_HOUR was the most important predictor for DELAY_OR_NOT. We then tested each model to see if any other predictors held a relatively higher importance among all predictors except SCHED_DEP_HOUR. By plotting the probability of DELAY vs. SCHED_DEP_HOUR and a second predictor, we could determine if the second predictor had a significant effect on DELAY. However, in all the graphs, DELAY was only positively related to SCHED_DEP_HOUR: the later the SCHED_DEP_HOUR, the higher the probability of DELAY"
      ],
      "metadata": {
        "id": "1hdGs6Fy2wdQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class='exercise-r'>\n",
        "\n",
        "**5.**\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "-5DTUjOR20ac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def progressbar(n_step, n_total):\n",
        "    \"\"\"Prints self-updating progress bar to stdout to track for-loop progress\n",
        "    \n",
        "    There are entire 3rd-party libraries dedicated to custom progress-bars.\n",
        "    A simple function like this is often more than enough to get the job done.\n",
        "    \n",
        "    :param n_total: total number of expected for-loop iterations\n",
        "    :type n_total: int\n",
        "    :param n_step: current iteration number, starting at 0\n",
        "    :type n_step: int\n",
        "\n",
        "    .. example::\n",
        "    \n",
        "        for i in range(n_iterations):\n",
        "            progressbar(i, n_iterations)\n",
        "            \n",
        "    .. source:\n",
        "    \n",
        "        This function is a simplified version of code found here:\n",
        "        https://stackoverflow.com/questions/3160699/python-progress-bar/15860757#15860757\n",
        "    \"\"\"\n",
        "    n_step = n_step + 1\n",
        "    barlen = 50\n",
        "    progress = n_step / n_total\n",
        "    block = int(round(barlen * progress))\n",
        "    status = \"\"\n",
        "    if n_step == n_total:\n",
        "        status = \"Done...\\r\\n\\n\"\n",
        "    text = \"\\r [{0}] {1}/{2} {3}\".format(\n",
        "        \"=\" * block + \"-\" * (barlen - block),\n",
        "        n_step,\n",
        "        n_total,\n",
        "        status,\n",
        "    )\n",
        "    sys.stdout.write(text)\n",
        "    sys.stdout.flush()"
      ],
      "metadata": {
        "id": "5_F2aw3A2_vB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# set a max round for bootstrapping\n",
        "MAX_BOOTSTRAP = 50\n",
        "\n",
        "# save predictions and histories in seperate lists\n",
        "histories   = []\n",
        "evaluations = []\n",
        "predictions = []\n",
        "\n",
        "# start bootstrapping and training\n",
        "for cnt in range(MAX_BOOTSTRAP):\n",
        "    # use progress bar to show current progress\n",
        "    progressbar(cnt, MAX_BOOTSTRAP)\n",
        "\n",
        "    # define my new_model with the same architectures\n",
        "    new_model = tf.keras.Sequential()\n",
        "    new_model.add(tf.keras.layers.Dense(15, input_dim=X_train.shape[1], activation='relu'))\n",
        "    new_model.add(tf.keras.layers.Dense(15, activation='relu'))\n",
        "    new_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "    new_model.compile(  # compile the model\n",
        "        loss = LOSS_,\n",
        "        optimizer = OPTMZ_,\n",
        "        metrics = METRIC_\n",
        "    )\n",
        "    \n",
        "    # create new training set using bootstrapping\n",
        "    X_train_bstrap, y_train_bstrap = resample(X_train, y_train) #,n_samples=int(X_train.shape[0]/MAX_BOOTSTRAP))\n",
        "\n",
        "    # fit the model with new training set\n",
        "    new_history = new_model.fit(\n",
        "        x = X_train_bstrap,\n",
        "        y = y_train_bstrap,\n",
        "        epochs = EPOCHS,\n",
        "        validation_split = 0.2,\n",
        "        verbose = 0\n",
        "    )\n",
        "    histories.append(new_history)\n",
        "\n",
        "    # get predictions on fixed X test\n",
        "    new_pred_test = new_model.predict(X_test, verbose = 0)\n",
        "    predictions.append(new_pred_test)\n",
        "\n",
        "    # get evaluation result on fixed X test\n",
        "    new_eval_test = new_model.evaluate(X_test, y_test, verbose = 0)\n",
        "    evaluations.append(new_eval_test)\n",
        "    \n",
        "    # delete this model\n",
        "    del new_model\n"
      ],
      "metadata": {
        "id": "_WMaYXy43Crm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# randomly generate 8 indexs for y_test\n",
        "indexs = np.random.choice(len(y_test.index),8,replace=False)\n",
        "\n",
        "# plot 8 subplots\n",
        "fig, axs = plt.subplots(4,2,figsize=(12,16))\n",
        "\n",
        "for i in range(0,8):\n",
        "    ax = axs[i//2][i%2]\n",
        "\n",
        "    # get predicted probabilities of y_text[indexs[i]]\n",
        "    y_data = [predictions[p][indexs[i]][0] for p in range(0, MAX_BOOTSTRAP)]\n",
        "\n",
        "    # calculate confidence interval\n",
        "    y_mean = np.mean(y_data)\n",
        "    y_std = np.std(y_data)\n",
        "    low_CI_bound  = y_mean - 1.96*y_std\n",
        "    high_CI_bound = y_mean + 1.96*y_std\n",
        "    \n",
        "    # plot the distribution of predicted probabilities\n",
        "    t_str = f'Actual Class {y_test.iloc[indexs[i]].values[0]} (Test {indexs[i]})'\n",
        "    ax.set_title(t_str, fontsize=TITLE_FONTSIZE)\n",
        "    ax.set_xlabel('Predicted Probability', fontsize=AXIS_LABEL_SIZE)\n",
        "    ax.set_xticks(np.linspace(0,1,11))\n",
        "    ax.set_xlim(xmin=0, xmax=1)\n",
        "    ax.set_ylabel('Frequency', fontsize=AXIS_LABEL_SIZE)\n",
        "    ax.hist(y_data, bins=25, range=(0,1))\n",
        "\n",
        "    # plot confidence interval\n",
        "    ax.axvline(high_CI_bound, color='g')#,label=f'high bound {high_CI_bound:.2f}')\n",
        "    ax.axvline(low_CI_bound, color='g') #,label=f'low bound {low_CI_bound:.2f}')\n",
        "    ax.axvspan(low_CI_bound, high_CI_bound, alpha=0.1, label=f'95% CI [{low_CI_bound:.2f}, {high_CI_bound:.2f}]',color='g')\n",
        "    ax.legend()\n",
        "\n",
        "fig.suptitle('Distribution of Bootstrapped Probabilities with 95% CI\\n',fontsize=TITLE_FONTSIZE+2)\n",
        "fig.tight_layout()\n",
        "fig.subplots_adjust(hspace=0.3,wspace=0.2)\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "cKL_1-jk3I1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INTERPRETATION:**"
      ],
      "metadata": {
        "id": "TNuKzW8I3OC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the distribution of the predicted probabilities from eight randomly selected samples from the test observations. Each graph has a different 95% CI and the 95% CI represents how uncertain the prediction is. The wider the 95% CI is the more uncertain the prediction is. Thus these eight graphs show not only the distribution of predicted probabilities, but also how certain the prediction is for each graph."
      ],
      "metadata": {
        "id": "MlhF32Ti3QRK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class='exercise-r'>\n",
        "\n",
        "**6.**\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "y1HxOSsy3Rm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate PPR for all test samples\n",
        "predictions_array = np.array(predictions).reshape((len(predictions),-1))\n",
        "ppr_1 = (predictions_array < 0.5).mean(axis=0)\n",
        "ppr_2 = (predictions_array > 0.5).mean(axis=0)\n",
        "ppr = np.array([min(p1,p2) for p1,p2 in zip(ppr_1,ppr_2)])\n",
        "print(f'Number of PPR values: {len(ppr)}')\n",
        "\n",
        "# print the test accuracy for bagging model predictions\n",
        "pred_means = predictions_array.mean(axis=0)\n",
        "print(f'Bagging model test accuracy: {accuracy_score(y_test, pred_means.round())}')\n"
      ],
      "metadata": {
        "id": "jepuJV0l3aXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define my abstain bagging model\n",
        "def abstain_bagging_model(max_ppr):\n",
        "    \"\"\"\n",
        "     :function  the model only give a prediction for a particular observation\n",
        "                if ppr is lower than maximum ppr value.\n",
        "     :input     the threshold value of PPR (max 0.5)\n",
        "     :output    test accuracy, the proportion of those predicted\n",
        "    \"\"\"\n",
        "    \n",
        "    if max_ppr > 0.5:\n",
        "        max_ppr = 0.5\n",
        "\n",
        "    p_indexs = np.where(ppr <= max_ppr)\n",
        "\n",
        "    p_accuracy = accuracy_score(y_test.iloc[p_indexs].values, predictions_array.T[p_indexs].mean(axis=1).round())\n",
        "\n",
        "    p_proportion = len(p_indexs[0])/len(y_test)\n",
        "    \n",
        "    return p_accuracy, p_proportion\n"
      ],
      "metadata": {
        "id": "UV3fGatx3dEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,2,figsize=(12,3))\n",
        "\n",
        "# get x data(ppr) and y data(test accuracies and proportions)\n",
        "x_data = np.linspace(0, 0.5, 51)\n",
        "y1_data = []    # test accuracies\n",
        "y2_data = []    # proportions\n",
        "for p in x_data:\n",
        "    y1,y2 = abstain_bagging_model(p)\n",
        "    y1_data.append(y1)\n",
        "    y2_data.append(y2)\n",
        "\n",
        "# plot the test accuracies for an abstain bagging model\n",
        "ax[0].set_title(f'Test Accuracy for Abstain Bagging Model vs. PPR', fontsize=TITLE_FONTSIZE)\n",
        "ax[0].set_xlabel('Posterior Prediction Ratio (PPR)', fontsize=AXIS_LABEL_SIZE)\n",
        "ax[0].set_xticks(np.linspace(0,0.5,11))\n",
        "ax[0].set_xlim(xmin=0, xmax=0.5)\n",
        "ax[0].set_ylabel('Test Accuracy', fontsize=AXIS_LABEL_SIZE)\n",
        "ax[0].plot(x_data, y1_data, label='Accuracy')\n",
        "ax[0].legend()\n",
        "\n",
        "# plot the proportion of test observations not abstained\n",
        "ax[1].set_title(f'Proportion of Test Observations Not Abstained vs. PPR', fontsize=TITLE_FONTSIZE)\n",
        "ax[1].set_xlabel('Posterior Prediction Ratio (PPR)', fontsize=AXIS_LABEL_SIZE)\n",
        "ax[1].set_xticks(np.linspace(0,0.5,11))\n",
        "ax[1].set_xlim(xmin=0, xmax=0.5)\n",
        "ax[1].set_ylabel('Proportion', fontsize=AXIS_LABEL_SIZE)\n",
        "ax[1].plot(x_data, y2_data, label='Proportion')\n",
        "ax[1].legend()\n",
        "\n",
        "fig.tight_layout()\n",
        "fig.subplots_adjust(hspace=0.3,wspace=0.2)\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "3zQ8Oqkp3fOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INTERPRETATION:**"
      ],
      "metadata": {
        "id": "-fyfewAC3kqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From graph 1, we can see that as PPR increases the accuracy decreases. As shown by graph 2, we can see as the PPR increases the portion of test observations not abstained will increase. We can therefore infer that as the portion of test observations not abstained increases, the test oberserbations abstain decreases, so the accuracy deacreases."
      ],
      "metadata": {
        "id": "-bJW5EPM3lU4"
      }
    }
  ]
}